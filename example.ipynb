{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87b99955-7d21-44d4-819e-aa85d9cdff91",
   "metadata": {},
   "source": [
    "First, import the tools and define the object that will help us work with papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a828a0-3a3d-4bfd-bd27-4c799c9337c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litrevtools import LitrevTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dc07ab-7d34-45af-9f94-49554a67e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LitrevTools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf1465-b19d-44e8-8325-71a510f4a4e6",
   "metadata": {},
   "source": [
    "First, start with a list of papers. For example, take a few papers that come up on Google and Google Scholar when looking about causal representation learning (CRL), or that you might know are popular in this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f009279-6ba3-49fa-a933-a3f794ad7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "crl_titles_initial = [\n",
    "    'Towards Causal Representation Learning',\n",
    "    'Identifiable Causal Representation Learning: Unsupervised, Multi-View, and Multi-Environment',\n",
    "    'Interventional Causal Representation Learning',\n",
    "    'Linear Causal Disentanglement via Interventions'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325ab40-d5aa-477f-8d97-b5150c61ad8c",
   "metadata": {},
   "source": [
    "Compute how many total citations, and how many average citations per day they have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1f4838-a655-4d54-9e5e-236a57e0cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:26<00:00,  6.51s/it]\n"
     ]
    }
   ],
   "source": [
    "citations_dict = lt.citation_counts(crl_titles_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6644a19d-5128-490c-bc62-635cbb685b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citation counts': {'Towards Causal Representation Learning': 307,\n",
       "  'Identifiable Causal Representation Learning: Unsupervised, Multi-View, and Multi-Environment': 0,\n",
       "  'Interventional Causal Representation Learning': 66,\n",
       "  'Linear Causal Disentanglement via Interventions': 52},\n",
       " 'daily citation counts': {'Towards Causal Representation Learning': 0.22791388270230142,\n",
       "  'Identifiable Causal Representation Learning: Unsupervised, Multi-View, and Multi-Environment': 0.0,\n",
       "  'Interventional Causal Representation Learning': 0.0859375,\n",
       "  'Linear Causal Disentanglement via Interventions': 0.07407407407407407}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e23f78-d0bb-4b48-8de9-c1d9f0434d56",
   "metadata": {},
   "source": [
    "Now, how to find all CRL papers, or at least enough of them? A strategy is to find all papers citing or being cited these initial CRL papers and mentioning causal representation learning in their title or abstract. One of the initial papers launched the field, and another is a PhD thesis, so we expect them to have a citation or reference connection with all the relevant papers. As we see above, CRL can be referred to as \"causal representation learning\" but also \"causal disentanglement\". Thus, we run the following command, that finds all references and citations of the initial CRL papers, and have at least either of \"causal representation learning\" or \"causal disentanglement\" in their title or abstract. The below method uses the Semantic Scholar API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b71afc0-9888-4a23-87d1-23871d4eb090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:15<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "crl_titles = lt.bulldozer(crl_titles_initial, keywords = [\"causal representation learning\", \"causal disentanglement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46948510-7423-4970-965d-80a7c3609b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  continual learning of nonlinear independent representations\n",
      "2  :  identifiable exchangeable mechanisms for causal structure and representation learning\n",
      "3  :  causal representation learning from multiple distributions: a general setting\n",
      "4  :  when graph neural network meets causality: opportunities, methodologies and an outlook\n",
      "5  :  causal representation learning made identifiable by grouping of observational variables\n",
      "6  :  generative causal representation learning for out-of-distribution motion forecasting\n",
      "7  :  causal triplet: an open challenge for intervention-centric causal representation learning\n",
      "8  :  less data, more knowledge: building next generation semantic communication networks\n",
      "9  :  domain generalization - a causal perspective\n",
      "10  :  causal representation learning for instantaneous and temporal effects in interactive systems\n",
      "11  :  do-operation guided causal representation learning with reduced supervision strength\n",
      "12  :  causal machine learning for healthcare and precision medicine\n",
      "13  :  weakly supervised causal representation learning\n",
      "14  :  multi-instance causal representation learning for instance label prediction and out-of-distribution generalization\n",
      "15  :  generative multitask learning mitigates target-causing confounding\n",
      "16  :  citris: causal identifiability from temporal intervened sequences\n",
      "17  :  toward causal representation learning\n",
      "18  :  connectivity-contrastive learning: combining causal discovery and representation learning for multimodal data\n",
      "19  :  survey on trustworthy graph neural networks: from a causal perspective\n",
      "20  :  edinburgh research explorer causal machine learning for healthcare and precision medicine\n",
      "21  :  language agents meet causality -- bridging llms and causal world models\n",
      "22  :  unifying causal representation learning with the invariance principle\n",
      "23  :  causal representation learning for gan-generated face image quality assessment\n",
      "24  :  linear causal disentanglement via higher-order cumulants\n",
      "25  :  diffusion-based causal representation learning\n",
      "26  :  linear causal representation learning from unknown multi-node interventions\n",
      "27  :  marrying causal representation learning with dynamical systems for science\n",
      "28  :  identifiable latent neural causal models\n",
      "29  :  a sparsity principle for partially observable causal representation learning\n",
      "30  :  implicit causal representation learning via switchable mechanisms\n",
      "31  :  learning interpretable concepts: unifying causal representation learning and foundation models\n",
      "32  :  invariance & causal representation learning: prospects and limitations\n",
      "33  :  multi-view causal representation learning with partial observability\n",
      "34  :  identifying linearly-mixed causal representations from multi-node interventions\n",
      "35  :  object-centric architectures enable efficient causal representation learning\n",
      "36  :  identifiable latent polynomial causal models through the lens of change\n",
      "37  :  general identifiability and achievability for causal representation learning\n",
      "38  :  from identifiable causal representations to controllable counterfactual generation: a survey on causal generative modeling\n",
      "39  :  identifying representations for intervention extrapolation\n",
      "40  :  multi-domain causal representation learning via weak distributional invariances\n",
      "41  :  identifiability guarantees for causal disentanglement from soft interventions\n",
      "42  :  a causal ordering prior for unsupervised representation learning\n",
      "43  :  learning causally disentangled representations via the principle of independent causal mechanisms\n",
      "44  :  nonparametric identifiability of causal representations from unknown interventions\n",
      "45  :  causal component analysis\n",
      "46  :  disentanglement of latent representations via sparse causal interventions\n",
      "47  :  unpaired multi-domain causal representation learning\n",
      "48  :  score-based causal representation learning with interventions\n",
      "49  :  score-based causal representation learning from interventions: nonparametric identifiability\n",
      "50  :  icitris: causal representation learning for instantaneous temporal effects\n",
      "51  :  targeted reduction of causal models\n",
      "52  :  causal disentanglement of multimodal data\n",
      "53  :  o bject - centric architectures enable efficient causal representation learning\n",
      "54  :  weight-variant latent causal models\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(crl_titles):\n",
    "    print(idx+1, ' : ', title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46136f3-eda8-4173-b160-11c75c6ba3c1",
   "metadata": {},
   "source": [
    "We also check the CRL papers published on arXiV in September 2024, using the arXiV API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9d661d-451c-45b4-a174-9627866af2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "crl_titles_arxiv = lt.parse_arxiv(start='2024-09-01', end='2024-09-30', keywords = [\"causal representation learning\", \"causal disentanglement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc9cad8-97e5-4900-a8c4-490ecc557bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  Identifying Weight-Variant Latent Causal Models\n",
      "2  :  Unifying Causal Representation Learning with the Invariance Principle\n",
      "3  :  Celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling\n",
      "4  :  CauSkelNet: Causal Representation Learning for Human Behaviour Analysis\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(crl_titles_arxiv):\n",
    "    print(idx+1, ' : ', title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde1abb-34f6-475f-a407-a1913574411d",
   "metadata": {},
   "source": [
    "Papers Celcomen and CauSkelNet of this arXiV list are not in the above list. This might be fixed by doing another round of the bulldozer method, normally finding all \"missed\" papers that were previously forgotten. We also specify that we do not want the initial CRL papers, in addition to the input papers, to be returned in this new search, through the queue parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2122dce-c1a5-4542-b4c5-1e02da554125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████████████████████▎                                             | 32/54 [01:54<01:13,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No result ! <-  invariance & causal representation learning: prospects and limitations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [02:56<00:00,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "crl_titles_bis = lt.bulldozer(crl_titles, queue = crl_titles_initial + crl_titles, keywords = [\"causal representation learning\", \"causal disentanglement\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99aecffb-b5fe-43a6-9972-2f463b14f4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772\n",
      "2  :  on the identification of temporally causal representation with instantaneous dependence\n",
      "3  :  a twist for graph classification: optimizing causal information flow in graph neural networks\n",
      "4  :  weakly supervised disentangled generative causal representation learning\n",
      "5  :  invariant causal representation learning for out-of-distribution generalization\n",
      "6  :  identifying weight-variant latent causal models\n",
      "7  :  causal reasoning: charting a revolutionary course for next-generation ai-native wireless networks\n",
      "8  :  causal disentanglement with network information for debiased recommendations\n",
      "9  :  learning causal representation for training cross-domain pose estimator via generative interventions\n",
      "10  :  disentangled generative causal representation learning\n",
      "11  :  towards the reusability and compositionality of causal representations\n",
      "12  :  biscuit: causal representation learning from binary interactions\n",
      "13  :  look, learn and leverage (l3): mitigating visual-domain shift and discovering intrinsic relations via symbolic alignment\n",
      "14  :  shadow datasets, new challenging datasets for causal representation learning\n",
      "15  :  causal diffusion autoencoders: toward counterfactual generation via diffusion probabilistic models\n",
      "16  :  relation-first modeling paradigm for causal representation learning toward the development of agi\n",
      "17  :  realization of causal representation learning to adjust confounding bias in latent space\n",
      "18  :  realization of causal representation learning and redefined dag for causal ai\n",
      "19  :  causal representation learning in temporal data via single-parent decoding\n",
      "20  :  causal representation learning through higher-level information extraction\n",
      "21  :  sparsity regularization via tree-structured environments for disentangled representations\n",
      "22  :  diffusion based causal representation learning\n",
      "23  :  c-disentanglement: discovering causally-independent generative factors under an inductive bias of confounder\n",
      "24  :  scm-vae: learning identifiable causal representations via structural knowledge\n",
      "25  :  model-free causal reinforcement learning with causal diagrams\n",
      "26  :  nonlinear invariant risk minimization: a causal approach\n",
      "27  :  causal representation learning via counterfactual intervention\n",
      "28  :  causal factor disentanglement for few-shot domain adaptation in video prediction\n",
      "29  :  temporally disentangled representation learning under unknown nonstationarity\n",
      "30  :  possible principles for aligned structure learning agents\n",
      "31  :  towards generalizable reinforcement learning via causality-guided self-adaptive representations\n",
      "32  :  unbiased semantic representation learning based on causal disentanglement for domain generalization\n",
      "33  :  causal disentanglement domain generalization for time-series signal fault diagnosis\n",
      "34  :  controllable image generation based on causal representation learning\n",
      "35  :  de-age confounder based causal representation learning for cuffless blood pressure estimation\n",
      "36  :  learning causal representations from general environments: identifiability and intrinsic ambiguity\n",
      "37  :  interpretability is in the mind of the beholder: a causal framework for human-interpretable representation learning\n",
      "38  :  measuring the effect of causal disentanglement on the adversarial robustness of neural network models\n",
      "39  :  learning causality-inspired representation consistency for video anomaly detection\n",
      "40  :  leveraging task structures for improved identifiability in neural network representations\n",
      "41  :  unbiased scene graph generation via two-stage causal modeling\n",
      "42  :  towards causal representation learning and deconfounding from indefinite data\n",
      "43  :  fault diagnosis for high‐speed train braking system based on disentangled causal representation learning\n",
      "44  :  a survey on causal representation learning and future work for medical image analysis\n",
      "45  :  language-based causal representation learning\n",
      "46  :  improving multi-task generalization via regularizing spurious correlation\n",
      "47  :  causal representation learning for out-of-distribution recommendation\n",
      "48  :  translational lung imaging analysis through disentangled representations\n",
      "49  :  on causally disentangled representations\n",
      "50  :  3didentbox: a toolbox for identifiability benchmarking\n",
      "51  :  advances in causal representation learning: discovery of the hidden world\n",
      "52  :  an adversarial perspective on accuracy, robustness, fairness, and privacy: multilateral-tradeoffs in trustworthy ml\n",
      "53  :  causalvae: structured causal disentanglement in variational autoencoder\n",
      "54  :  score-based causal representation learning: linear and general transformations\n",
      "55  :  causal disentanglement\n",
      "56  :  celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(crl_titles_bis):\n",
    "    print(idx+1, ' : ', title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b1915-708f-4b97-8ce3-b5e82fed736f",
   "metadata": {},
   "source": [
    "Thus, the Celcomen paper has now been found by the bulldozer method. The CauSkelNet is still not included, but a quick look of its Semantic Scholar shows that it does not have any reference or citation with the keywords \"causal representation learning\" or \"causal disentanglement\". This shows the bulldozer method should be complemented with more \"naive\" ways of finding papers, eg by a simple search on Google Scholar or Semantic Scholar.\n",
    "\n",
    "Next, say that actually we only care about CRL methods that are score-based and have identifiability results. The further methods further filters the found CRL papers that have both \"score\" and \"identif\" (that encapsulates words such as \"identify\", \"identifiability\", or \"identifiable\") in their title or abstract. We also manually review and select every filtered paper ; notably, this requires the user's intervention. As you can see, for the keywords, tuples encode \"and\", and lists encode \"or\". The keywords argument can be made even more recursive, e.g. having `['x', ('y', 'z')]` which means \" x or (y and z)\". Unlike the bulldozer method for references and citations, here abstracts are being looked for on arXiV, then Semantic Scholar if not found on arXiV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe73533e-7707-4e7b-85fa-f48e6f359281",
   "metadata": {},
   "outputs": [],
   "source": [
    "crl_titles_all = crl_titles_initial +  crl_titles + crl_titles_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2676ba40-4676-4468-8003-bca29d340fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting abstracts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/114 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying title 'Towards Causal Representation Learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                               | 1/114 [00:02<04:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'Identifiable Causal Representation Learning: Unsupervised, Multi-View, and Multi-Environment' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                                              | 2/114 [00:04<04:03,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'Interventional Causal Representation Learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▉                                                                                                             | 3/114 [00:06<03:42,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'Linear Causal Disentanglement via Interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▉                                                                                                            | 4/114 [00:06<02:40,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'continual learning of nonlinear independent representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▉                                                                                                           | 5/114 [00:08<02:38,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifiable exchangeable mechanisms for causal structure and representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▉                                                                                                          | 6/114 [00:09<02:21,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning from multiple distributions: a general setting' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████▉                                                                                                         | 7/114 [00:10<02:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'when graph neural network meets causality: opportunities, methodologies and an outlook' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▊                                                                                                        | 8/114 [00:11<01:59,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning made identifiable by grouping of observational variables' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████▊                                                                                                       | 9/114 [00:11<01:48,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'generative causal representation learning for out-of-distribution motion forecasting' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████▋                                                                                                     | 10/114 [00:14<02:30,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal triplet: an open challenge for intervention-centric causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▋                                                                                                    | 11/114 [00:16<02:50,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'less data, more knowledge: building next generation semantic communication networks' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████████▋                                                                                                   | 12/114 [00:17<02:16,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'domain generalization - a causal perspective' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████████▋                                                                                                  | 13/114 [00:19<02:43,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning for instantaneous and temporal effects in interactive systems' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▋                                                                                                 | 14/114 [00:19<02:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'do-operation guided causal representation learning with reduced supervision strength' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████████▌                                                                                                | 15/114 [00:22<02:32,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal machine learning for healthcare and precision medicine' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▌                                                                                               | 16/114 [00:22<02:09,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'weakly supervised causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████▌                                                                                              | 17/114 [00:23<01:48,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'multi-instance causal representation learning for instance label prediction and out-of-distribution generalization' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████████▌                                                                                             | 18/114 [00:25<02:10,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'generative multitask learning mitigates target-causing confounding' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▌                                                                                            | 19/114 [00:27<02:33,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'citris: causal identifiability from temporal intervened sequences' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████▍                                                                                           | 20/114 [00:28<02:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'toward causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▍                                                                                          | 21/114 [00:29<02:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'connectivity-contrastive learning: combining causal discovery and representation learning for multimodal data' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "connectivity-contrastive learning: combining causal discovery and representation learning for multimodal data\n",
      "Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning\n",
      "Got None when trying title 'connectivity-contrastive learning: combining causal discovery and representation learning for multimodal data' with 'arxiv'\n",
      "Trying title 'connectivity-contrastive learning: combining causal discovery and representation learning for multimodal data' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████▍                                                                                         | 22/114 [00:32<02:50,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'survey on trustworthy graph neural networks: from a causal perspective' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████▍                                                                                        | 23/114 [00:34<02:55,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'edinburgh research explorer causal machine learning for healthcare and precision medicine' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "edinburgh research explorer causal machine learning for healthcare and precision medicine\n",
      "Causal Machine Learning for Healthcare and Precision Medicine\n",
      "Got None when trying title 'edinburgh research explorer causal machine learning for healthcare and precision medicine' with 'arxiv'\n",
      "Trying title 'edinburgh research explorer causal machine learning for healthcare and precision medicine' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████████████▎                                                                                       | 24/114 [00:37<03:11,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Weird paperdict, some vital fields (author, year and/or title) are missing. Imputing what's missing with NA. Please check the original paperdict:  {'title': 'Edinburgh Research Explorer Causal Machine Learning for Healthcare and Precision Medicine', 'author': \"Pedro Sanchez and J. Voisey and Tian Xia and Hannah I. Watson and Alison Q. O'Neil and S. Tsaftaris\", 'ENTRYTYPE': 'misc', 'ID': 'None', 'abstract': 'Causal machine learning (CML) has experienced increasing popularity in health-care. Beyond the inherent capabilities of adding domain knowledge into learning systems, CML provides a complete toolset for investigating how a system would react to an intervention (e.g. outcome given a treatment). Quantifying effects of interventions allows actionable decisions to be made whilst maintaining robustness in the presence of confounders. Here, we explore how causal inference can be incorporated into different aspects of clinical decision support (CDS) systems by using recent advances in machine learning. Throughout this paper, we use Alzheimer’s disease (AD) to create examples for illustrating how CML can be advantageous in clinical scenarios. Furthermore, we discuss important challenges present in healthcare applications such as processing high-dimensional and un-structured data, generalisation to out-of-distribution samples, and temporal relationships, that despite the great effort from the research community remain to be solved. Finally, we review lines of research within causal representation learning, causal discovery and causal reasoning which offer the potential towards addressing the aforementioned challenges.'}\n",
      "Trying title 'language agents meet causality -- bridging llms and causal world models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████▎                                                                                      | 25/114 [00:38<02:34,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'unifying causal representation learning with the invariance principle' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████████████████████▎                                                                                     | 26/114 [00:39<02:11,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning for gan-generated face image quality assessment' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal representation learning for gan-generated face image quality assessment\n",
      "Image Content Generation with Causal Reasoning\n",
      "Got None when trying title 'causal representation learning for gan-generated face image quality assessment' with 'arxiv'\n",
      "Trying title 'causal representation learning for gan-generated face image quality assessment' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████▎                                                                                    | 27/114 [00:51<07:05,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'linear causal disentanglement via higher-order cumulants' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████████▎                                                                                   | 28/114 [00:53<05:43,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'diffusion-based causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████▏                                                                                  | 29/114 [00:55<04:46,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'linear causal representation learning from unknown multi-node interventions' with 'arxiv'\n",
      "Error in Google Search without proxy - trying with proxy\n",
      "Google search crashed\n",
      "Got None when trying title 'linear causal representation learning from unknown multi-node interventions' with 'arxiv'\n",
      "Trying title 'linear causal representation learning from unknown multi-node interventions' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 357, in search_google\n",
      "    return next(url for url in google_search_module(query))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 379, in search_arxiv\n",
      "    id_list=[self.search_google(title + ' site:arxiv.org').split('/')[-1]],\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 364, in search_google\n",
      "    raise \"No proxy available! Error!\"\n",
      "TypeError: exceptions must derive from BaseException\n",
      " 26%|█████████████████████████████▏                                                                                 | 30/114 [00:57<03:52,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'marrying causal representation learning with dynamical systems for science' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████████████▏                                                                                | 31/114 [00:57<02:57,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifiable latent neural causal models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████▏                                                                               | 32/114 [00:58<02:28,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'a sparsity principle for partially observable causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████████████▏                                                                              | 33/114 [00:59<02:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'implicit causal representation learning via switchable mechanisms' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████████████                                                                              | 34/114 [01:00<01:39,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning interpretable concepts: unifying causal representation learning and foundation models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████                                                                             | 35/114 [01:00<01:23,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'invariance & causal representation learning: prospects and limitations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████                                                                            | 36/114 [01:01<01:21,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'multi-view causal representation learning with partial observability' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████████████████                                                                           | 37/114 [01:04<01:46,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifying linearly-mixed causal representations from multi-node interventions' with 'arxiv'\n",
      "Error in Google Search without proxy - trying with proxy\n",
      "Google search crashed\n",
      "Got None when trying title 'identifying linearly-mixed causal representations from multi-node interventions' with 'arxiv'\n",
      "Trying title 'identifying linearly-mixed causal representations from multi-node interventions' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 357, in search_google\n",
      "    return next(url for url in google_search_module(query))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 379, in search_arxiv\n",
      "    id_list=[self.search_google(title + ' site:arxiv.org').split('/')[-1]],\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 364, in search_google\n",
      "    raise \"No proxy available! Error!\"\n",
      "TypeError: exceptions must derive from BaseException\n",
      " 33%|█████████████████████████████████████                                                                          | 38/114 [01:05<01:41,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'object-centric architectures enable efficient causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████████████▉                                                                         | 39/114 [01:07<01:59,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifiable latent polynomial causal models through the lens of change' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████████████▉                                                                        | 40/114 [01:08<01:38,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'general identifiability and achievability for causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████████████▉                                                                       | 41/114 [01:11<02:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'from identifiable causal representations to controllable counterfactual generation: a survey on causal generative modeling' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████████████▉                                                                      | 42/114 [01:11<01:44,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifying representations for intervention extrapolation' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████████████▊                                                                     | 43/114 [01:12<01:29,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'multi-domain causal representation learning via weak distributional invariances' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████████████▊                                                                    | 44/114 [01:14<01:50,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifiability guarantees for causal disentanglement from soft interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████████████████████████████████████▊                                                                   | 45/114 [01:15<01:29,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'a causal ordering prior for unsupervised representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████▊                                                                  | 46/114 [01:17<01:37,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causally disentangled representations via the principle of independent causal mechanisms' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████████████████████▊                                                                 | 47/114 [01:18<01:22,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'nonparametric identifiability of causal representations from unknown interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████████████████▋                                                                | 48/114 [01:18<01:13,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal component analysis' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|███████████████████████████████████████████████▋                                                               | 49/114 [01:19<01:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'disentanglement of latent representations via sparse causal interventions' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "disentanglement of latent representations via sparse causal interventions\n",
      "Disentanglement of Latent Representations via Causal Interventions\n",
      "Got None when trying title 'disentanglement of latent representations via sparse causal interventions' with 'arxiv'\n",
      "Trying title 'disentanglement of latent representations via sparse causal interventions' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████████████████▋                                                              | 50/114 [01:21<01:28,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'unpaired multi-domain causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████████████████▋                                                             | 51/114 [01:23<01:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning with interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████████████▋                                                            | 52/114 [01:25<01:41,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "score-based causal representation learning from interventions: nonparametric identifiability\n",
      "Score-based Causal Representation Learning with Interventions\n",
      "Got None when trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████████████████▌                                                           | 53/114 [01:38<05:13,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Weird paperdict, some vital fields (author, year and/or title) are missing. Imputing what's missing with NA. Please check the original paperdict:  {'title': 'Score-based Causal Representation Learning from Interventions: Nonparametric Identifiability', 'author': 'Burak Varici and Emre Acartürk and Karthikeyan Shanmugam and A. Tajer', 'ENTRYTYPE': 'misc', 'ID': 'None', 'abstract': 'This paper focuses on causal representation learning (CRL) under a general non-parametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two (stochastic) hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the existing identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. It is noteworthy that the existing results on non-parametric identifiability require assumptions on interventions and additional faithfulness assumptions. This paper shows that when observational data is available, additional faithfulness assumptions are unnecessary.'}\n",
      "Trying title 'icitris: causal representation learning for instantaneous temporal effects' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "icitris: causal representation learning for instantaneous temporal effects\n",
      "Causal Representation Learning for Instantaneous and Temporal Effects in Interactive Systems\n",
      "Got None when trying title 'icitris: causal representation learning for instantaneous temporal effects' with 'arxiv'\n",
      "Trying title 'icitris: causal representation learning for instantaneous temporal effects' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████████████████▌                                                          | 54/114 [01:41<04:28,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'targeted reduction of causal models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████▌                                                         | 55/114 [01:42<03:15,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal disentanglement of multimodal data' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████████████████▌                                                        | 56/114 [01:43<02:29,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'o bject - centric architectures enable efficient causal representation learning' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "o bject - centric architectures enable efficient causal representation learning\n",
      "Object-centric architectures enable efficient causal representation learning\n",
      "Got None when trying title 'o bject - centric architectures enable efficient causal representation learning' with 'arxiv'\n",
      "Trying title 'o bject - centric architectures enable efficient causal representation learning' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████▌                                                       | 57/114 [01:45<02:24,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Weird paperdict, some vital fields (author, year and/or title) are missing. Imputing what's missing with NA. Please check the original paperdict:  {'title': 'O BJECT - CENTRIC ARCHITECTURES ENABLE EFFICIENT CAUSAL REPRESENTATION LEARNING', 'ENTRYTYPE': 'misc', 'ID': 'None', 'abstract': 'only addresses injectivity failures, but also results in a significant reduction in the number of perturbations we need to observe to disentangle properties using Ahuja et al. (2022b)’s approach. We illustrate these results by developing a property disentanglement algorithm that combines Zhang et al. (2023)’s SA-MESH object-centric architecture with Ahuja et al. (2022b)’s approach to disentangle-ment and show that our approach is very effective at disentangling the properties of objects on both 2D and 3D synthetic benchmarks.'}\n",
      "Trying title 'weight-variant latent causal models' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "weight-variant latent causal models\n",
      "Identifying Weight-Variant Latent Causal Models\n",
      "Got None when trying title 'weight-variant latent causal models' with 'arxiv'\n",
      "Trying title 'weight-variant latent causal models' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████████████████▍                                                      | 58/114 [01:48<02:25,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772' with 'arxiv'\n",
      "Error in Google Search without proxy - trying with proxy\n",
      "Google search crashed\n",
      "Got None when trying title 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772' with 'arxiv'\n",
      "Trying title 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 357, in search_google\n",
      "    return next(url for url in google_search_module(query))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 379, in search_arxiv\n",
      "    id_list=[self.search_google(title + ' site:arxiv.org').split('/')[-1]],\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 364, in search_google\n",
      "    raise \"No proxy available! Error!\"\n",
      "TypeError: exceptions must derive from BaseException\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 469, in paperdict\n",
      "    paperdict = paperdict_methods_dict[source](title)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 414, in _paperdict_semanticscholar\n",
      "    fields = self._get_fields_from_pub(pub, fields='citationStyles,openAccessPdf,abstract')\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 51, in _get_fields_from_pub\n",
      "    id = pub['paperId']\n",
      "         ~~~^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      " 52%|█████████████████████████████████████████████████████████▍                                                     | 59/114 [01:49<02:04,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug when trying title 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772' with 'semanticscholar'\n",
      "Got None when trying title 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772' with 'semanticscholar'\n",
      "WARNING : ALWAYS GOT NONE FOR 'uni-fying causal representation learning with the invariance principle, september 2024. url http://arxiv.org/abs/2409.02772'\n",
      "Trying title 'on the identification of temporally causal representation with instantaneous dependence' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████████████████████▍                                                    | 60/114 [01:50<01:36,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'a twist for graph classification: optimizing causal information flow in graph neural networks' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "a twist for graph classification: optimizing causal information flow in graph neural networks\n",
      "When Graph Neural Network Meets Causality: Opportunities, Methodologies and An Outlook\n",
      "Got None when trying title 'a twist for graph classification: optimizing causal information flow in graph neural networks' with 'arxiv'\n",
      "Trying title 'a twist for graph classification: optimizing causal information flow in graph neural networks' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████████████████████▍                                                   | 61/114 [01:53<01:49,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'weakly supervised disentangled generative causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████████▎                                                  | 62/114 [01:53<01:24,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'invariant causal representation learning for out-of-distribution generalization' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "invariant causal representation learning for out-of-distribution generalization\n",
      "Learning Causally Invariant Representations for Out-of-Distribution Generalization on Graphs\n",
      "Got None when trying title 'invariant causal representation learning for out-of-distribution generalization' with 'arxiv'\n",
      "Trying title 'invariant causal representation learning for out-of-distribution generalization' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████████████████████████▎                                                 | 63/114 [01:56<01:38,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'identifying weight-variant latent causal models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████▎                                                | 64/114 [01:58<01:30,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal reasoning: charting a revolutionary course for next-generation ai-native wireless networks' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████████████████████▎                                               | 65/114 [01:59<01:28,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal disentanglement with network information for debiased recommendations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████████████████████▎                                              | 66/114 [02:00<01:09,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causal representation for training cross-domain pose estimator via generative interventions' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "learning causal representation for training cross-domain pose estimator via generative interventions\n",
      "Causal Deep Learning\n",
      "Got None when trying title 'learning causal representation for training cross-domain pose estimator via generative interventions' with 'arxiv'\n",
      "Trying title 'learning causal representation for training cross-domain pose estimator via generative interventions' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████████████████████████████████████████████████████▏                                             | 67/114 [02:03<01:30,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'disentangled generative causal representation learning' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "disentangled generative causal representation learning\n",
      "Weakly Supervised Disentangled Generative Causal Representation Learning\n",
      "Got None when trying title 'disentangled generative causal representation learning' with 'arxiv'\n",
      "Trying title 'disentangled generative causal representation learning' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████▏                                            | 68/114 [02:07<01:50,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'towards the reusability and compositionality of causal representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████████████████████████▏                                           | 69/114 [02:07<01:23,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'biscuit: causal representation learning from binary interactions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████▏                                          | 70/114 [02:08<01:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'look, learn and leverage (l3): mitigating visual-domain shift and discovering intrinsic relations via symbolic alignment' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████████████████████▏                                         | 71/114 [02:10<01:11,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'shadow datasets, new challenging datasets for causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████████████████████                                         | 72/114 [02:11<00:57,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal diffusion autoencoders: toward counterfactual generation via diffusion probabilistic models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████████████████████                                        | 73/114 [02:11<00:46,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'relation-first modeling paradigm for causal representation learning toward the development of agi' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████████████                                       | 74/114 [02:13<00:51,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'realization of causal representation learning to adjust confounding bias in latent space' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████████                                      | 75/114 [02:14<00:44,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'realization of causal representation learning and redefined dag for causal ai' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "realization of causal representation learning and redefined dag for causal ai\n",
      "Realization of Causal Representation Learning to Adjust Confounding Bias in Latent Space\n",
      "Got None when trying title 'realization of causal representation learning and redefined dag for causal ai' with 'arxiv'\n",
      "Trying title 'realization of causal representation learning and redefined dag for causal ai' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████████████████████                                     | 76/114 [02:26<02:53,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning in temporal data via single-parent decoding' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████████████████████▉                                    | 77/114 [02:28<02:23,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning through higher-level information extraction' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal representation learning through higher-level information extraction\n",
      "Causal Representation Learning Made Identifiable by Grouping of Observational Variables\n",
      "Got None when trying title 'causal representation learning through higher-level information extraction' with 'arxiv'\n",
      "Trying title 'causal representation learning through higher-level information extraction' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████████████████▉                                   | 78/114 [02:33<02:23,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'sparsity regularization via tree-structured environments for disentangled representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████████████████████████▉                                  | 79/114 [02:35<02:04,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'diffusion based causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████▉                                 | 80/114 [02:37<01:42,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'c-disentanglement: discovering causally-independent generative factors under an inductive bias of confounder' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████████▊                                | 81/114 [02:39<01:32,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'scm-vae: learning identifiable causal representations via structural knowledge' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "scm-vae: learning identifiable causal representations via structural knowledge\n",
      "CausalVAE: Structured Causal Disentanglement in Variational Autoencoder\n",
      "Got None when trying title 'scm-vae: learning identifiable causal representations via structural knowledge' with 'arxiv'\n",
      "Trying title 'scm-vae: learning identifiable causal representations via structural knowledge' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████████████████████████████████████████████████████████▊                               | 82/114 [02:42<01:26,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'model-free causal reinforcement learning with causal diagrams' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "model-free causal reinforcement learning with causal diagrams\n",
      "Learning by Doing: An Online Causal Reinforcement Learning Framework with Causal-Aware Policy\n",
      "Got None when trying title 'model-free causal reinforcement learning with causal diagrams' with 'arxiv'\n",
      "Trying title 'model-free causal reinforcement learning with causal diagrams' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████████████████████████████████████████████████████▊                              | 83/114 [02:45<01:26,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'nonlinear invariant risk minimization: a causal approach' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████████████████▊                             | 84/114 [02:45<01:03,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning via counterfactual intervention' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal representation learning via counterfactual intervention\n",
      "Interventional Causal Representation Learning\n",
      "Got None when trying title 'causal representation learning via counterfactual intervention' with 'arxiv'\n",
      "Trying title 'causal representation learning via counterfactual intervention' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████▊                            | 85/114 [02:49<01:12,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal factor disentanglement for few-shot domain adaptation in video prediction' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal factor disentanglement for few-shot domain adaptation in video prediction\n",
      "Disentangled Representation Learning\n",
      "Got None when trying title 'causal factor disentanglement for few-shot domain adaptation in video prediction' with 'arxiv'\n",
      "Trying title 'causal factor disentanglement for few-shot domain adaptation in video prediction' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████████████████████████▋                           | 86/114 [02:51<01:12,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'temporally disentangled representation learning under unknown nonstationarity' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████████████████▋                          | 87/114 [02:52<00:53,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'possible principles for aligned structure learning agents' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████████████████████████▋                         | 88/114 [02:53<00:41,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'towards generalizable reinforcement learning via causality-guided self-adaptive representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████████████████████████▋                        | 89/114 [02:55<00:42,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'unbiased semantic representation learning based on causal disentanglement for domain generalization' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "unbiased semantic representation learning based on causal disentanglement for domain generalization\n",
      "Disentangled Representation Learning\n",
      "Got None when trying title 'unbiased semantic representation learning based on causal disentanglement for domain generalization' with 'arxiv'\n",
      "Trying title 'unbiased semantic representation learning based on causal disentanglement for domain generalization' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████████████████████████▋                       | 90/114 [02:58<00:50,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal disentanglement domain generalization for time-series signal fault diagnosis' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal disentanglement domain generalization for time-series signal fault diagnosis\n",
      "Causal Disentanglement Hidden Markov Model for Fault Diagnosis\n",
      "Got None when trying title 'causal disentanglement domain generalization for time-series signal fault diagnosis' with 'arxiv'\n",
      "Trying title 'causal disentanglement domain generalization for time-series signal fault diagnosis' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████▌                      | 91/114 [03:01<00:54,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'controllable image generation based on causal representation learning' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "controllable image generation based on causal representation learning\n",
      "Image Content Generation with Causal Reasoning\n",
      "Got None when trying title 'controllable image generation based on causal representation learning' with 'arxiv'\n",
      "Trying title 'controllable image generation based on causal representation learning' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████▌                     | 92/114 [03:05<01:03,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'de-age confounder based causal representation learning for cuffless blood pressure estimation' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 626, in _parse_feed\n",
      "    return self.__try_parse_feed(url, first_page=first_page, try_index=_try_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 663, in __try_parse_feed\n",
      "    raise HTTPError(url, try_index, resp.status_code)\n",
      "arxiv.HTTPError: Page request resulted in HTTP 400 (https://export.arxiv.org/api/query?search_query=&id_list=2024-08%3Fskip%3D2625%26show%3D2000&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 626, in _parse_feed\n",
      "    return self.__try_parse_feed(url, first_page=first_page, try_index=_try_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 663, in __try_parse_feed\n",
      "    raise HTTPError(url, try_index, resp.status_code)\n",
      "arxiv.HTTPError: Page request resulted in HTTP 400 (https://export.arxiv.org/api/query?search_query=&id_list=2024-08%3Fskip%3D2625%26show%3D2000&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 626, in _parse_feed\n",
      "    return self.__try_parse_feed(url, first_page=first_page, try_index=_try_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 663, in __try_parse_feed\n",
      "    raise HTTPError(url, try_index, resp.status_code)\n",
      "arxiv.HTTPError: Page request resulted in HTTP 400 (https://export.arxiv.org/api/query?search_query=&id_list=2024-08%3Fskip%3D2625%26show%3D2000&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 383, in search_arxiv\n",
      "    for result in arxiv.Client().results(arxiv_search):\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 579, in _results\n",
      "    feed = self._parse_feed(page_url, first_page=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 634, in _parse_feed\n",
      "    return self._parse_feed(url, first_page=first_page, _try_index=_try_index + 1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 634, in _parse_feed\n",
      "    return self._parse_feed(url, first_page=first_page, _try_index=_try_index + 1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 634, in _parse_feed\n",
      "    return self._parse_feed(url, first_page=first_page, _try_index=_try_index + 1)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 636, in _parse_feed\n",
      "    raise err\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 626, in _parse_feed\n",
      "    return self.__try_parse_feed(url, first_page=first_page, try_index=_try_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/cdllm_venv/lib/python3.12/site-packages/arxiv/__init__.py\", line 663, in __try_parse_feed\n",
      "    raise HTTPError(url, try_index, resp.status_code)\n",
      "arxiv.HTTPError: Page request resulted in HTTP 400 (https://export.arxiv.org/api/query?search_query=&id_list=2024-08%3Fskip%3D2625%26show%3D2000&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google search crashed\n",
      "Got None when trying title 'de-age confounder based causal representation learning for cuffless blood pressure estimation' with 'arxiv'\n",
      "Trying title 'de-age confounder based causal representation learning for cuffless blood pressure estimation' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████████████████████████▌                    | 93/114 [03:18<02:04,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causal representations from general environments: identifiability and intrinsic ambiguity' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████████████████████████████▌                   | 94/114 [03:19<01:31,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'interpretability is in the mind of the beholder: a causal framework for human-interpretable representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████████████████████████████▌                  | 95/114 [03:21<01:12,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'measuring the effect of causal disentanglement on the adversarial robustness of neural network models' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████▍                 | 96/114 [03:22<00:51,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causality-inspired representation consistency for video anomaly detection' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████▍                | 97/114 [03:24<00:45,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'leveraging task structures for improved identifiability in neural network representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████████████████████████████████▍               | 98/114 [03:25<00:35,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'unbiased scene graph generation via two-stage causal modeling' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████▍              | 99/114 [03:28<00:33,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'towards causal representation learning and deconfounding from indefinite data' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████▍             | 100/114 [03:28<00:25,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'fault diagnosis for high‐speed train braking system based on disentangled causal representation learning' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "fault diagnosis for high‐speed train braking system based on disentangled causal representation learning\n",
      "Causal Machine Learning: A Survey and Open Problems\n",
      "Got None when trying title 'fault diagnosis for high‐speed train braking system based on disentangled causal representation learning' with 'arxiv'\n",
      "Trying title 'fault diagnosis for high‐speed train braking system based on disentangled causal representation learning' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████▍            | 101/114 [03:33<00:33,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'a survey on causal representation learning and future work for medical image analysis' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████▍           | 102/114 [03:34<00:26,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'language-based causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████▍          | 103/114 [03:37<00:26,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'improving multi-task generalization via regularizing spurious correlation' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 104/114 [03:41<00:28,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal representation learning for out-of-distribution recommendation' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal representation learning for out-of-distribution recommendation\n",
      "Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation\n",
      "Got None when trying title 'causal representation learning for out-of-distribution recommendation' with 'arxiv'\n",
      "Trying title 'causal representation learning for out-of-distribution recommendation' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 105/114 [03:55<00:56,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'translational lung imaging analysis through disentangled representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 106/114 [03:56<00:37,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'on causally disentangled representations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 107/114 [03:57<00:24,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title '3didentbox: a toolbox for identifiability benchmarking' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "3didentbox: a toolbox for identifiability benchmarking\n",
      "Natural Counterfactuals With Necessary Backtracking\n",
      "Got None when trying title '3didentbox: a toolbox for identifiability benchmarking' with 'arxiv'\n",
      "Trying title '3didentbox: a toolbox for identifiability benchmarking' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏     | 108/114 [04:00<00:20,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "advances in causal representation learning: discovery of the hidden world\n",
      "Discovery of the Hidden World with Large Language Models\n",
      "Got None when trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 109/114 [04:03<00:16,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'an adversarial perspective on accuracy, robustness, fairness, and privacy: multilateral-tradeoffs in trustworthy ml' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "an adversarial perspective on accuracy, robustness, fairness, and privacy: multilateral-tradeoffs in trustworthy ml\n",
      "SoK: Unintended Interactions among Machine Learning Defenses and Risks\n",
      "Got None when trying title 'an adversarial perspective on accuracy, robustness, fairness, and privacy: multilateral-tradeoffs in trustworthy ml' with 'arxiv'\n",
      "Trying title 'an adversarial perspective on accuracy, robustness, fairness, and privacy: multilateral-tradeoffs in trustworthy ml' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 110/114 [04:06<00:13,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causalvae: structured causal disentanglement in variational autoencoder' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████   | 111/114 [04:07<00:07,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning: linear and general transformations' with 'arxiv'\n",
      "Error in Google Search without proxy - trying with proxy\n",
      "Google search crashed\n",
      "Got None when trying title 'score-based causal representation learning: linear and general transformations' with 'arxiv'\n",
      "Trying title 'score-based causal representation learning: linear and general transformations' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 357, in search_google\n",
      "    return next(url for url in google_search_module(query))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 379, in search_arxiv\n",
      "    id_list=[self.search_google(title + ' site:arxiv.org').split('/')[-1]],\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 364, in search_google\n",
      "    raise \"No proxy available! Error!\"\n",
      "TypeError: exceptions must derive from BaseException\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 112/114 [04:09<00:04,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'causal disentanglement' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "causal disentanglement\n",
      "Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms\n",
      "Got None when trying title 'causal disentanglement' with 'arxiv'\n",
      "Trying title 'causal disentanglement' with 'semanticscholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████ | 113/114 [04:13<00:02,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles do not correspond :\n",
      "causal disentanglement\n",
      "Identifiability Guarantees for Causal Disentanglement from Soft Interventions\n",
      "Got None when trying title 'causal disentanglement' with 'semanticscholar'\n",
      "WARNING : ALWAYS GOT NONE FOR 'causal disentanglement'\n",
      "Trying title 'celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 114/114 [04:15<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  linear causal representation learning from unknown multi-node interventions\n",
      "title found  :  Linear Causal Representation Learning from Unknown Multi-node Interventions\n",
      "abstract  :  Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▊                                                                                              | 1/6 [04:18<21:31, 258.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  general identifiability and achievability for causal representation learning\n",
      "title found  :  General Identifiability and Achievability for Causal Representation Learning\n",
      "abstract  :  This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████████████████████████████▋                                                                           | 2/6 [04:19<07:07, 106.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  score-based causal representation learning from interventions: nonparametric identifiability\n",
      "title found  :  Score-based Causal Representation Learning from Interventions: Nonparametric Identifiability\n",
      "abstract  :  This paper focuses on causal representation learning (CRL) under a general non-parametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two (stochastic) hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the existing identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. It is noteworthy that the existing results on non-parametric identifiability require assumptions on interventions and additional faithfulness assumptions. This paper shows that when observational data is available, additional faithfulness assumptions are unnecessary.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████                                                         | 3/6 [04:19<02:54, 58.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  learning causal representations from general environments: identifiability and intrinsic ambiguity\n",
      "title found  :  Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity\n",
      "abstract  :  We study causal representation learning, the task of recovering high-level latent variables and their causal relationships in the form of a causal graph from low-level observed data (such as text and images), assuming access to observations generated from multiple environments. Prior results on the identifiability of causal representations typically assume access to single-node interventions which is rather unrealistic in practice, since the latent variables are unknown in the first place. In this work, we provide the first identifiability results based on data that stem from general environments. We show that for linear causal models, while the causal graph can be fully recovered, the latent variables are only identified up to the surrounded-node ambiguity (SNA) \\citep{varici2023score}. We provide a counterpart of our guarantee, showing that SNA is basically unavoidable in our setting. We also propose an algorithm, \\texttt{LiNGCReL} which provably recovers the ground-truth model up to SNA, and we demonstrate its effectiveness via numerical experiments. Finally, we consider general non-parametric causal models and show that the same identification barrier holds when assuming access to groups of soft single-node interventions.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████                                      | 4/6 [04:20<01:10, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  advances in causal representation learning: discovery of the hidden world\n",
      "title found  :  Advances in Causal Representation Learning: Discovery of the Hidden World\n",
      "abstract  :  Can we find the causal direction between two random variables without temporal precedence information? How can we figure out where latent causal variables should be and how they are related? In our daily life and science, people often attempt to answer such causal questions for the purpose of understanding, proper manipulation of systems, and robust prediction under interventions. Accordingly, finding causality and making use of it is an essential problem in scientific discovery and engineering. Traditional causal discovery approaches [1], such as the PC algorithm and GES, mainly focus on finding causal relations among measured variables, even in the presence of latent confounders (see, e.g., the FCI algorithm). However, in a wide range of real problems, we even do not know what the causal variables are or they are not measurable. That is, measured variables (e.g., image pixels values, insurance claims, and survey responses) are often reflections of the underlying causal variables involved in the generating process, but not the causal variables themselves. For instance, in psychometric studies, the answer scores to questionnaire questions are not directly causally related, but generated by the underlying mental conditions, which might be causally related to each other. Causal representation learning aims to reveal the underlying high-level hidden causal variables, their causal relations, and how they are causally related to the measured variables [2]. It can be seen as a special case of causal discovery. To achieve reliable causal discovery and causal representation learning, two issues are to be addressed. One is to formulate what footprint or constraints causality leaves in observational data; the other is how to guarantee that the estimated result is consistent with the underlying causal process. Interestingly, the modularity property of a causal system implies properties of minimal changes and independent changes in causal modules, and we show that instantiations of such properties make it possible to recover the underlying causal representations from observational data with identifiability guarantees: under appropriate assumptions, the learned representations are consistent with the underlying causal process up to certain types of indeterminacies.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████                   | 5/6 [04:20<00:22, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "title requested  :  score-based causal representation learning: linear and general transformations\n",
      "title found  :  Score-based Causal Representation Learning: Linear and General Transformations\n",
      "abstract  :  This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.\n",
      " \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Add this title?  (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [04:20<00:00, 43.47s/it]\n"
     ]
    }
   ],
   "source": [
    "crl_titles_filtered = lt.filter(crl_titles_all, keywords = (\"score\", \"identif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fff696f-df30-4265-8df7-cee8caea6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  linear causal representation learning from unknown multi-node interventions\n",
      "2  :  general identifiability and achievability for causal representation learning\n",
      "3  :  score-based causal representation learning from interventions: nonparametric identifiability\n",
      "4  :  learning causal representations from general environments: identifiability and intrinsic ambiguity\n",
      "5  :  advances in causal representation learning: discovery of the hidden world\n",
      "6  :  score-based causal representation learning: linear and general transformations\n"
     ]
    }
   ],
   "source": [
    "for idx, title in enumerate(crl_titles_filtered):\n",
    "    print(idx+1, ' : ', title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fcd9d-0531-4c90-9ba5-08cc75d1b638",
   "metadata": {},
   "source": [
    "We download the papers in the home folder. Note that we could download as many papers as we want, including all previously found CRL papers. To do so, the titles are searched from arXiV, then Google Scholar if the former does not work, then Semantic Scholar (which can be set up in the \"sources\" argument of the method, see the code). Note that Google Scholar typically requires a proxy to work, as the API is VERY quick to raise a rate limit error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "979961e6-25a9-45f5-8a6e-c0034103dc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying title 'linear causal representation learning from unknown multi-node interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████                                                                                               | 1/6 [00:01<00:09,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'general identifiability and achievability for causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████                                                                            | 2/6 [00:04<00:09,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "score-based causal representation learning from interventions: nonparametric identifiability\n",
      "Score-based Causal Representation Learning with Interventions\n",
      "Got None when trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'googlescholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████                                                         | 3/6 [00:12<00:14,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causal representations from general environments: identifiability and intrinsic ambiguity' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████                                      | 4/6 [00:13<00:06,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "advances in causal representation learning: discovery of the hidden world\n",
      "Discovery of the Hidden World with Large Language Models\n",
      "Got None when trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'googlescholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████                   | 5/6 [00:21<00:04,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning: linear and general transformations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:23<00:00,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file varici2023sbcrlfini.pdf from https://openreview.net/pdf?id=MytNJ6lXAV\n",
      "Downloaded file varıcı2024lcrlfumni.pdf from http://arxiv.org/pdf/2406.05937v1\n",
      "Downloaded file varıcı2024giaafcrl.pdf from http://arxiv.org/pdf/2310.15450v2\n",
      "Downloaded file jin2024lcrfgeiaia.pdf from http://arxiv.org/pdf/2311.12267v2\n",
      "Downloaded file varıcı2024sbcrllagt.pdf from http://arxiv.org/pdf/2402.00849v3\n",
      "Downloaded file zhangNAaicrldothw.pdf from http://cogsys.org/symposium/discovery-2023/abstracts/Abstract_5108.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'venue': '… Learning Workshop at …',\n",
       "  'title': 'Score-based causal representation learning from interventions: Nonparametric identifiability',\n",
       "  'year': '2023',\n",
       "  'booktitle': 'Causal Representation Learning Workshop at NeurIPS 2023',\n",
       "  'author': 'Varici, Burak and Acart{\\\\\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali',\n",
       "  'abstract': 'This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes** identifiability** and** achievability** results using two (stochastic) hard** uncoupled** interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'varici2023sbcrlfini',\n",
       "  'url': 'https://openreview.net/pdf?id=MytNJ6lXAV'},\n",
       " {'url': 'http://arxiv.org/pdf/2406.05937v1',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'eprint': '2406.05937',\n",
       "  'year': '2024',\n",
       "  'author': 'Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Ali Tajer',\n",
       "  'title': 'Linear Causal Representation Learning from Unknown Multi-node Interventions',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'varıcı2024lcrlfumni',\n",
       "  'abstract': 'Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.'},\n",
       " {'url': 'http://arxiv.org/pdf/2310.15450v2',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'eprint': '2310.15450',\n",
       "  'year': '2024',\n",
       "  'author': 'Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Ali Tajer',\n",
       "  'title': 'General Identifiability and Achievability for Causal Representation Learning',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'varıcı2024giaafcrl',\n",
       "  'abstract': 'This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.'},\n",
       " {'url': 'http://arxiv.org/pdf/2311.12267v2',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'eprint': '2311.12267',\n",
       "  'year': '2024',\n",
       "  'author': 'Jikai Jin and Vasilis Syrgkanis',\n",
       "  'title': 'Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'jin2024lcrfgeiaia',\n",
       "  'abstract': 'We study causal representation learning, the task of recovering high-level latent variables and their causal relationships in the form of a causal graph from low-level observed data (such as text and images), assuming access to observations generated from multiple environments. Prior results on the identifiability of causal representations typically assume access to single-node interventions which is rather unrealistic in practice, since the latent variables are unknown in the first place. In this work, we provide the first identifiability results based on data that stem from general environments. We show that for linear causal models, while the causal graph can be fully recovered, the latent variables are only identified up to the surrounded-node ambiguity (SNA) \\\\citep{varici2023score}. We provide a counterpart of our guarantee, showing that SNA is basically unavoidable in our setting. We also propose an algorithm, \\\\texttt{LiNGCReL} which provably recovers the ground-truth model up to SNA, and we demonstrate its effectiveness via numerical experiments. Finally, we consider general non-parametric causal models and show that the same identification barrier holds when assuming access to groups of soft single-node interventions.'},\n",
       " {'url': 'http://arxiv.org/pdf/2402.00849v3',\n",
       "  'primaryclass': 'cs.LG',\n",
       "  'archiveprefix': 'arXiv',\n",
       "  'eprint': '2402.00849',\n",
       "  'year': '2024',\n",
       "  'author': 'Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Abhishek Kumar and Ali Tajer',\n",
       "  'title': 'Score-based Causal Representation Learning: Linear and General Transformations',\n",
       "  'ENTRYTYPE': 'misc',\n",
       "  'ID': 'varıcı2024sbcrllagt',\n",
       "  'abstract': 'This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.'},\n",
       " {'venue': 'NA',\n",
       "  'title': 'Advances in Causal Representation Learning: Discovery of the Hidden World',\n",
       "  'year': 'NA',\n",
       "  'author': 'Zhang, Kun',\n",
       "  'abstract': 'Can we find the causal direction between two random variables without temporal precedence information? How can we figure out where latent causal variables should be and how they are related? In our daily life and science, people often attempt to answer such causal questions for the purpose of understanding, proper manipulation of systems, and robust prediction under interventions. Accordingly, finding causality and making use of it is an essential problem in scientific discovery and engineering. Traditional causal discovery',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'zhangNAaicrldothw',\n",
       "  'url': 'http://cogsys.org/symposium/discovery-2023/abstracts/Abstract_5108.pdf'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt.download(crl_titles_filtered, '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f4bd7-68af-41f7-ae04-7a62d08c6490",
   "metadata": {},
   "source": [
    "Finally, we print their bibtexs. These were actually also retrieved and used in the former download method, papers are then downloaded from the \"url\" field of the bibtexs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a71d234-3061-4983-832b-b7b241e9c775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying title 'linear causal representation learning from unknown multi-node interventions' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████████                                                                                               | 1/6 [00:01<00:07,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'general identifiability and achievability for causal representation learning' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████                                                                            | 2/6 [00:03<00:07,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "score-based causal representation learning from interventions: nonparametric identifiability\n",
      "Score-based Causal Representation Learning with Interventions\n",
      "Got None when trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'arxiv'\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'own'\n",
      "Bug when trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'own'\n",
      "Got None when trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'own'\n",
      "Trying title 'score-based causal representation learning from interventions: nonparametric identifiability' with 'googlescholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 469, in paperdict\n",
      "    paperdict = paperdict_methods_dict[source](title)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 436, in _paperdict_own\n",
      "    if os.path.exists(self.folder):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen genericpath>\", line 19, in exists\n",
      "TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      " 50%|█████████████████████████████████████████████████████████                                                         | 3/6 [00:10<00:12,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'learning causal representations from general environments: identifiability and intrinsic ambiguity' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████                                      | 4/6 [00:10<00:05,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Titles do not correspond :\n",
      "advances in causal representation learning: discovery of the hidden world\n",
      "Discovery of the Hidden World with Large Language Models\n",
      "Got None when trying title 'advances in causal representation learning: discovery of the hidden world' with 'arxiv'\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'own'\n",
      "Bug when trying title 'advances in causal representation learning: discovery of the hidden world' with 'own'\n",
      "Got None when trying title 'advances in causal representation learning: discovery of the hidden world' with 'own'\n",
      "Trying title 'advances in causal representation learning: discovery of the hidden world' with 'googlescholar'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 469, in paperdict\n",
      "    paperdict = paperdict_methods_dict[source](title)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/oscar.clivio/causal_discovery_llm/researchtools/litrevtools.py\", line 436, in _paperdict_own\n",
      "    if os.path.exists(self.folder):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen genericpath>\", line 19, in exists\n",
      "TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████                   | 5/6 [00:17<00:04,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n",
      "Trying title 'score-based causal representation learning: linear and general transformations' with 'arxiv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:19<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bibtexs = lt.bibtexs(crl_titles_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3b3e16-96b6-40ee-9777-3bed7e604fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@misc{jin2024lcrfgeiaia,\n",
      " abstract = {We study causal representation learning, the task of recovering high-level latent variables and their causal relationships in the form of a causal graph from low-level observed data (such as text and images), assuming access to observations generated from multiple environments. Prior results on the identifiability of causal representations typically assume access to single-node interventions which is rather unrealistic in practice, since the latent variables are unknown in the first place. In this work, we provide the first identifiability results based on data that stem from general environments. We show that for linear causal models, while the causal graph can be fully recovered, the latent variables are only identified up to the surrounded-node ambiguity (SNA) \\citep{varici2023score}. We provide a counterpart of our guarantee, showing that SNA is basically unavoidable in our setting. We also propose an algorithm, \\texttt{LiNGCReL} which provably recovers the ground-truth model up to SNA, and we demonstrate its effectiveness via numerical experiments. Finally, we consider general non-parametric causal models and show that the same identification barrier holds when assuming access to groups of soft single-node interventions.},\n",
      " archiveprefix = {arXiv},\n",
      " author = {Jikai Jin and Vasilis Syrgkanis},\n",
      " eprint = {2311.12267},\n",
      " primaryclass = {cs.LG},\n",
      " title = {Learning Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity},\n",
      " url = {http://arxiv.org/pdf/2311.12267v2},\n",
      " year = {2024}\n",
      "}\n",
      "\n",
      "@inproceedings{varici2023sbcrlfini,\n",
      " abstract = {This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes** identifiability** and** achievability** results using two (stochastic) hard** uncoupled** interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect},\n",
      " author = {Varici, Burak and Acart{\\\"u}rk, Emre and Shanmugam, Karthikeyan and Tajer, Ali},\n",
      " booktitle = {Causal Representation Learning Workshop at NeurIPS 2023},\n",
      " title = {Score-based causal representation learning from interventions: Nonparametric identifiability},\n",
      " url = {https://openreview.net/pdf?id=MytNJ6lXAV},\n",
      " venue = {… Learning Workshop at …},\n",
      " year = {2023}\n",
      "}\n",
      "\n",
      "@misc{varıcı2024giaafcrl,\n",
      " abstract = {This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary.},\n",
      " archiveprefix = {arXiv},\n",
      " author = {Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Ali Tajer},\n",
      " eprint = {2310.15450},\n",
      " primaryclass = {cs.LG},\n",
      " title = {General Identifiability and Achievability for Causal Representation Learning},\n",
      " url = {http://arxiv.org/pdf/2310.15450v2},\n",
      " year = {2024}\n",
      "}\n",
      "\n",
      "@misc{varıcı2024lcrlfumni,\n",
      " abstract = {Despite the multifaceted recent advances in interventional causal representation learning (CRL), they primarily focus on the stylized assumption of single-node interventions. This assumption is not valid in a wide range of applications, and generally, the subset of nodes intervened in an interventional environment is fully unknown. This paper focuses on interventional CRL under unknown multi-node (UMN) interventional environments and establishes the first identifiability results for general latent causal models (parametric or nonparametric) under stochastic interventions (soft or hard) and linear transformation from the latent to observed space. Specifically, it is established that given sufficiently diverse interventional environments, (i) identifiability up to ancestors is possible using only soft interventions, and (ii) perfect identifiability is possible using hard interventions. Remarkably, these guarantees match the best-known results for more restrictive single-node interventions. Furthermore, CRL algorithms are also provided that achieve the identifiability guarantees. A central step in designing these algorithms is establishing the relationships between UMN interventional CRL and score functions associated with the statistical models of different interventional environments. Establishing these relationships also serves as constructive proof of the identifiability guarantees.},\n",
      " archiveprefix = {arXiv},\n",
      " author = {Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Ali Tajer},\n",
      " eprint = {2406.05937},\n",
      " primaryclass = {cs.LG},\n",
      " title = {Linear Causal Representation Learning from Unknown Multi-node Interventions},\n",
      " url = {http://arxiv.org/pdf/2406.05937v1},\n",
      " year = {2024}\n",
      "}\n",
      "\n",
      "@misc{varıcı2024sbcrllagt,\n",
      " abstract = {This paper addresses intervention-based causal representation learning (CRL) under a general nonparametric latent causal model and an unknown transformation that maps the latent variables to the observed variables. Linear and general transformations are investigated. The paper addresses both the identifiability and achievability aspects. Identifiability refers to determining algorithm-agnostic conditions that ensure recovering the true latent causal variables and the latent causal graph underlying them. Achievability refers to the algorithmic aspects and addresses designing algorithms that achieve identifiability guarantees. By drawing novel connections between score functions (i.e., the gradients of the logarithm of density functions) and CRL, this paper designs a score-based class of algorithms that ensures both identifiability and achievability. First, the paper focuses on linear transformations and shows that one stochastic hard intervention per node suffices to guarantee identifiability. It also provides partial identifiability guarantees for soft interventions, including identifiability up to ancestors for general causal models and perfect latent graph recovery for sufficiently non-linear causal models. Secondly, it focuses on general transformations and shows that two stochastic hard interventions per node suffice for identifiability. Notably, one does not need to know which pair of interventional environments have the same node intervened. Finally, the theoretical results are empirically validated via experiments on structured synthetic data and image data.},\n",
      " archiveprefix = {arXiv},\n",
      " author = {Burak Varıcı and Emre Acartürk and Karthikeyan Shanmugam and Abhishek Kumar and Ali Tajer},\n",
      " eprint = {2402.00849},\n",
      " primaryclass = {cs.LG},\n",
      " title = {Score-based Causal Representation Learning: Linear and General Transformations},\n",
      " url = {http://arxiv.org/pdf/2402.00849v3},\n",
      " year = {2024}\n",
      "}\n",
      "\n",
      "@article{zhangNAaicrldothw,\n",
      " abstract = {Can we find the causal direction between two random variables without temporal precedence information? How can we figure out where latent causal variables should be and how they are related? In our daily life and science, people often attempt to answer such causal questions for the purpose of understanding, proper manipulation of systems, and robust prediction under interventions. Accordingly, finding causality and making use of it is an essential problem in scientific discovery and engineering. Traditional causal discovery},\n",
      " author = {Zhang, Kun},\n",
      " title = {Advances in Causal Representation Learning: Discovery of the Hidden World},\n",
      " url = {http://cogsys.org/symposium/discovery-2023/abstracts/Abstract_5108.pdf},\n",
      " venue = {NA},\n",
      " year = {NA}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bibtexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945dc68-4a48-4dfe-9a88-58859abc3c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f5e5e-5e2c-4adb-ae42-d7534c12100f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bd1b5-6de9-446c-80b1-f990ac8c4393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da567eca-86d6-4952-ab3a-39a2ec52fdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
